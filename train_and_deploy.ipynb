{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS fine-tuning Resnet 18 for image classification using SageMaker\n",
    "\n",
    "This notebook lists all the steps that you need to complete the complete this project. You will need to complete all the TODOs in this notebook as well as in the README and the two python scripts included with the starter code.\n",
    "\n",
    "This project is part of the AWS Machine Learning Engineer Nanodegree requisites. It consists in the fine-tuning of a pretrained big image classification model (Resnet 18) using SageMaker, the main AWS tool for machine learning developing and deploying. The project will re train the last fully connected layer of the model with a new set of images from https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip, that consists in dozens of different images of dog breeds, labeled with the corresponding dog's breed. Then we will test the accuracy of the model in recognizing different breeds.\n",
    "In the process of getting this job done, we will perform a search of best hyperparameteres and monitorize the re-training of the model by using the Sagemaker hyperparameter tuner, profiler and debugger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting smdebug\n",
      "  Using cached smdebug-1.0.12-py2.py3-none-any.whl (270 kB)\n",
      "Collecting pyinstrument==3.4.2\n",
      "  Using cached pyinstrument-3.4.2-py2.py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from smdebug) (20.1)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /opt/conda/lib/python3.7/site-packages (from smdebug) (1.20.23)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from smdebug) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from smdebug) (1.20.3)\n",
      "Collecting pyinstrument-cext>=0.2.2\n",
      "  Using cached pyinstrument_cext-0.2.4-cp37-cp37m-manylinux2010_x86_64.whl (20 kB)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.23 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (1.23.23)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (0.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->smdebug) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->smdebug) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.23->boto3>=1.10.32->smdebug) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.23->boto3>=1.10.32->smdebug) (1.26.7)\n",
      "Installing collected packages: pyinstrument-cext, pyinstrument, smdebug\n",
      "Successfully installed pyinstrument-3.4.2 pyinstrument-cext-0.2.4 smdebug-1.0.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# TODO: Install any packages that you might need\n",
    "# For instance, you will need the smdebug package\n",
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bucket: project3dogsimagesclassification\n",
      "AWS Region: us-east-1\n",
      "RoleArn: arn:aws:iam::187401717515:role/service-role/AmazonSageMaker-ExecutionRole-20220110T092400\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import any packages that you might need\n",
    "# For instance you will need Boto3 and Sagemaker\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "bucket= \"project3dogsimagesclassification\"## TODO: fill in\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "\n",
    "import boto3\n",
    "region = boto3.Session().region_name ## TODO: fill in## TODO: fill in\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "role = get_execution_role() ## TODO: fill in\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "In this cell we download the zip file containing the images ditributed in three subdirectories: train (train set) valid (validation set) test (test set)\n",
    "\n",
    "Within those dirs there are sub folders with a number and a name of the dog's breed images it contain. Those directory names will serve as labels for our images.\n",
    "\n",
    "The !(bang sign) means execute a command in console First, we download the file by using the wget linux command Second, we unzip the file by using the zip linux command\n",
    "\n",
    "These folders with images go to newly created folders into the file system of the machine that SageMaker is using. Then, another command, aws performs the copy from the local machine file system to the s3 resource of our AWS account. Those files in S3 are ready to be consumed by our model, provided the rol we asigned to the SageMaker session has rights to read/write over our S3 resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fetch and upload the data to AWS S3\n",
    "#run once only\n",
    "# Command to download and unzip data\n",
    "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip dogImages.zip\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls dogImages/ | tail\n",
    "\"\"\"\n",
    "!mkdir dogImages/train/resguardo\n",
    "!mv dogImages/train/00* dogImages/train/resguardo/\n",
    "!mv dogImages/train/010* dogImages/train/resguardo/\n",
    "!mv dogImages/train/011* dogImages/train/resguardo/\n",
    "!mv dogImages/train/012* dogImages/train/resguardo/\n",
    "!mv dogImages/train/013* dogImages/train/resguardo/\n",
    "!mkdir dogImages/train/basura/\n",
    "!mv dogImages/train/0* dogImages/train/basura/\n",
    "!mv dogImages/train/1* dogImages/train/basura/\n",
    "!rm -fr dogImages/train/basura/\n",
    "!mv dogImages/train/resguardo/* dogImages/train/ \n",
    "!rmdir dogImages/train/resguardo/\n",
    "!ls dogImages/train/ \n",
    "\n",
    "!mkdir dogImages/test/resguardo\n",
    "!mv dogImages/test/00* dogImages/test/resguardo/\n",
    "!mv dogImages/test/010* dogImages/test/resguardo/\n",
    "!mv dogImages/test/011* dogImages/test/resguardo/\n",
    "!mv dogImages/test/012* dogImages/test/resguardo/\n",
    "!mv dogImages/test/013* dogImages/test/resguardo/\n",
    "!mkdir dogImages/test/basura/\n",
    "!mv dogImages/test/0* dogImages/test/basura/\n",
    "!mv dogImages/test/1* dogImages/test/basura/\n",
    "!rm -fr dogImages/test/basura/\n",
    "!mv dogImages/test/resguardo/* dogImages/test/ \n",
    "!rmdir dogImages/test/resguardo/\n",
    "!ls dogImages/test/ \n",
    "\n",
    "\n",
    "!mkdir dogImages/valid/resguardo\n",
    "!mv dogImages/valid/00* dogImages/valid/resguardo/\n",
    "!mv dogImages/valid/010* dogImages/valid/resguardo/\n",
    "!mv dogImages/valid/011* dogImages/valid/resguardo/\n",
    "!mv dogImages/valid/012* dogImages/valid/resguardo/\n",
    "!mv dogImages/valid/013* dogImages/valid/resguardo/\n",
    "!mkdir dogImages/valid/basura/\n",
    "!mv dogImages/valid/0* dogImages/valid/basura/\n",
    "!mv dogImages/valid/1* dogImages/valid/basura/\n",
    "!rm -fr dogImages/valid/basura/\n",
    "!mv dogImages/valid/resguardo/* dogImages/valid/ \n",
    "!rmdir dogImages/valid/resguardo/\n",
    "!ls dogImages/valid/ \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001.Affenpinscher\t\t    068.Flat-coated_retriever\n",
      "002.Afghan_hound\t\t    069.French_bulldog\n",
      "003.Airedale_terrier\t\t    070.German_pinscher\n",
      "004.Akita\t\t\t    071.German_shepherd_dog\n",
      "005.Alaskan_malamute\t\t    072.German_shorthaired_pointer\n",
      "006.American_eskimo_dog\t\t    073.German_wirehaired_pointer\n",
      "007.American_foxhound\t\t    074.Giant_schnauzer\n",
      "008.American_staffordshire_terrier  075.Glen_of_imaal_terrier\n",
      "009.American_water_spaniel\t    076.Golden_retriever\n",
      "010.Anatolian_shepherd_dog\t    077.Gordon_setter\n",
      "011.Australian_cattle_dog\t    078.Great_dane\n",
      "012.Australian_shepherd\t\t    079.Great_pyrenees\n",
      "013.Australian_terrier\t\t    080.Greater_swiss_mountain_dog\n",
      "014.Basenji\t\t\t    081.Greyhound\n",
      "015.Basset_hound\t\t    082.Havanese\n",
      "016.Beagle\t\t\t    083.Ibizan_hound\n",
      "017.Bearded_collie\t\t    084.Icelandic_sheepdog\n",
      "018.Beauceron\t\t\t    085.Irish_red_and_white_setter\n",
      "019.Bedlington_terrier\t\t    086.Irish_setter\n",
      "020.Belgian_malinois\t\t    087.Irish_terrier\n",
      "021.Belgian_sheepdog\t\t    088.Irish_water_spaniel\n",
      "022.Belgian_tervuren\t\t    089.Irish_wolfhound\n",
      "023.Bernese_mountain_dog\t    090.Italian_greyhound\n",
      "024.Bichon_frise\t\t    091.Japanese_chin\n",
      "025.Black_and_tan_coonhound\t    092.Keeshond\n",
      "026.Black_russian_terrier\t    093.Kerry_blue_terrier\n",
      "027.Bloodhound\t\t\t    094.Komondor\n",
      "028.Bluetick_coonhound\t\t    095.Kuvasz\n",
      "029.Border_collie\t\t    096.Labrador_retriever\n",
      "030.Border_terrier\t\t    097.Lakeland_terrier\n",
      "031.Borzoi\t\t\t    098.Leonberger\n",
      "032.Boston_terrier\t\t    099.Lhasa_apso\n",
      "033.Bouvier_des_flandres\t    100.Lowchen\n",
      "034.Boxer\t\t\t    101.Maltese\n",
      "035.Boykin_spaniel\t\t    102.Manchester_terrier\n",
      "036.Briard\t\t\t    103.Mastiff\n",
      "037.Brittany\t\t\t    104.Miniature_schnauzer\n",
      "038.Brussels_griffon\t\t    105.Neapolitan_mastiff\n",
      "039.Bull_terrier\t\t    106.Newfoundland\n",
      "040.Bulldog\t\t\t    107.Norfolk_terrier\n",
      "041.Bullmastiff\t\t\t    108.Norwegian_buhund\n",
      "042.Cairn_terrier\t\t    109.Norwegian_elkhound\n",
      "043.Canaan_dog\t\t\t    110.Norwegian_lundehund\n",
      "044.Cane_corso\t\t\t    111.Norwich_terrier\n",
      "045.Cardigan_welsh_corgi\t    112.Nova_scotia_duck_tolling_retriever\n",
      "046.Cavalier_king_charles_spaniel   113.Old_english_sheepdog\n",
      "047.Chesapeake_bay_retriever\t    114.Otterhound\n",
      "048.Chihuahua\t\t\t    115.Papillon\n",
      "049.Chinese_crested\t\t    116.Parson_russell_terrier\n",
      "050.Chinese_shar-pei\t\t    117.Pekingese\n",
      "051.Chow_chow\t\t\t    118.Pembroke_welsh_corgi\n",
      "052.Clumber_spaniel\t\t    119.Petit_basset_griffon_vendeen\n",
      "053.Cocker_spaniel\t\t    120.Pharaoh_hound\n",
      "054.Collie\t\t\t    121.Plott\n",
      "055.Curly-coated_retriever\t    122.Pointer\n",
      "056.Dachshund\t\t\t    123.Pomeranian\n",
      "057.Dalmatian\t\t\t    124.Poodle\n",
      "058.Dandie_dinmont_terrier\t    125.Portuguese_water_dog\n",
      "059.Doberman_pinscher\t\t    126.Saint_bernard\n",
      "060.Dogue_de_bordeaux\t\t    127.Silky_terrier\n",
      "061.English_cocker_spaniel\t    128.Smooth_fox_terrier\n",
      "062.English_setter\t\t    129.Tibetan_mastiff\n",
      "063.English_springer_spaniel\t    130.Welsh_springer_spaniel\n",
      "064.English_toy_spaniel\t\t    131.Wirehaired_pointing_griffon\n",
      "065.Entlebucher_mountain_dog\t    132.Xoloitzcuintli\n",
      "066.Field_spaniel\t\t    133.Yorkshire_terrier\n",
      "067.Finnish_spitz\n"
     ]
    }
   ],
   "source": [
    "!ls dogImages/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"DEFAULT_S3_BUCKET\"] = bucket\n",
    "!aws s3 sync ./dogImages/train s3://${DEFAULT_S3_BUCKET}/dogImages/train/\n",
    "!aws s3 sync ./dogImages/test s3://${DEFAULT_S3_BUCKET}/dogImages/test/\n",
    "!aws s3 sync ./dogImages/valid s3://${DEFAULT_S3_BUCKET}/dogImages/valid/\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "**TODO:** This is the part where you will finetune a pretrained model with hyperparameter tuning. Remember that you have to tune a minimum of two hyperparameters. However you are encouraged to tune more. You are also encouraged to explain why you chose to tune those particular hyperparameters and the ranges.\n",
    "\n",
    "**Note:** You will need to use the `hpo.py` script to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your HP ranges, metrics etc.\n",
    "import os #for avoiding run the former cell\n",
    "os.environ[\"DEFAULT_S3_BUCKET\"] = bucket\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.001, 0.1),\n",
    "    #The epsilon for adam and rmsprop. It is usually set to a small value to avoid division by 0 (around 1e-8).\n",
    "    #\"eps\": ContinuousParameter(1e-9, 1e-7), #no lo vamos a usar. vamos a usar adam y no AdamW\n",
    "    \"batch_size\": CategoricalParameter([16, 64, 256, 1024]),\n",
    "    #\"weight_decay\": ContinuousParameter(1e-3, 1e-1),#option if using AdamW\n",
    "    \"epochs\": IntegerParameter(2, 4)\n",
    "    #\"epochs\": IntegerParameter(2, 8)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "#temporal:\n",
    "#Best hyperparameters from hpo:\n",
    "#lr: 0.0921110950826238\n",
    "#batch_size: 256\n",
    "#epochs: 3\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.092, 0.0924),\n",
    "    \"batch_size\": CategoricalParameter([256, 257]),\n",
    "    \"epochs\": IntegerParameter(3, 4)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "objective_metric_name = \"Accuracy\"\n",
    "objective_type = \"Maximize\"\n",
    "metric_definitions = [{\"Name\": \"Accuracy\", \"Regex\": \"Accuracy: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create estimators for your HPs\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "#estimator = # TODO: Your estimator here\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"hpo.py\",\n",
    "    role=role,\n",
    "    py_version='py36',\n",
    "    framework_version=\"1.8\",\n",
    "    instance_count=1,\n",
    "    #sagemaker_session=session,\n",
    "    #source_dir=\"source\",\n",
    "    instance_type=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "\n",
    "#tuner = # TODO: Your HP tuner here\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=objective_type,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://project3dogsimagesclassification/dogImages\n",
      "s3://project3dogsimagesclassification/dogImages/train\n",
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit your HP Tuner\n",
    "#tuner.fit() # TODO: Remember to include your data channels\n",
    "#tuner.fit(wait=True)\n",
    "#path = \"s3://{}\".format(bucket) #works with the reduced dataset (10% of original) while working on the notebook\n",
    "path =  \"s3://{}/dogImages\".format(bucket) #we will use this when we have the complete dataset. \n",
    "#we tune only in the training set or val set too?\n",
    "#tuner.fit({\"train\": path + '/train' }, wait=True)\n",
    "print(path)\n",
    "print(path + '/train')\n",
    "tuner.fit({\n",
    "'train': path + '/train',     \n",
    "'valid': path + '/valid',  \n",
    "'test': path + '/test'     \n",
    "}, wait=True)\n",
    "#tuner.fit({'train': path + '/train'}, wait=True)\n",
    "#each line around 9min we wilc check using another kernel\n",
    "#9min per line using ml.g4dn.xlarge\n",
    "#using  ml.t3.medium start one line at 18:56:28, ends one line at 19:05:02 ttl 8:30min\n",
    "#second line ended at 19:14:05, 9:03min\n",
    "#third line ended at 19:23:00, 8:55min\n",
    "#fourth line ended at 19:31:55, 8:55min\n",
    "#fifth line ended at 19:40:55, 9:00min\n",
    "#sixth line ended at 19:50:40, 8:45min\n",
    "#seventh line never ended\n",
    "#eighth line is shorter\n",
    "\n",
    "#ml.t3.medium\n",
    "#1st 8:55:00 9min\n",
    "#2nd 9:04:00 9min\n",
    "#3rd 9:13:00 9min\n",
    "#4th 9:22:00 \n",
    "#5th 9:31\n",
    "#6th 9:40\n",
    "#7th 9:55\n",
    "#8th 10:04\n",
    "\n",
    "\n",
    "\n",
    "#8:53 fin 9:55:05, 1:02hs 7 lines\n",
    "#8:53 fin 10:03, 1:10hs 8 lines\n",
    "#ttl 70min with ml.t3.medium\n",
    "\n",
    "\n",
    "#started  15:10, ended 16:23 with smaller parameter range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the best estimators and the best HPs\n",
    "\n",
    "#best_estimator = #TODO\n",
    "best_estimator = tuner.best_estimator()\n",
    "\n",
    "#Get the hyperparameters of the best trained model\n",
    "best_estimator.hyperparameters()\n",
    "\n",
    "lr_b = float(best_estimator.hyperparameters()[\"lr\"])\n",
    "epochs_b = int(best_estimator.hyperparameters()['epochs'])\n",
    "#batch_size_b = int(best_estimator.hyperparameters()['batch_size']\n",
    "batch_size_b = int(best_estimator.hyperparameters()['batch_size'].replace('\"', \"\"))\n",
    "\n",
    "print(\"Best hyperparameters from hpo:\")\n",
    "print(\"lr:\",lr_b)\n",
    "print(\"batch_size:\",batch_size_b)\n",
    "print(\"epochs:\",epochs_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters from hpo:\n",
      "lr: 0.09223091926609225\n",
      "batch_size: 257\n",
      "epochs: 4\n"
     ]
    }
   ],
   "source": [
    "#Best hyperparameters from hpo to avoid re-running previous jobs\n",
    "lr_b = 0.09223091926609225\n",
    "batch_size_b = 257\n",
    "epochs_b = 4\n",
    "\n",
    "\n",
    "\n",
    "hyperparameters_b = {\n",
    "    \"lr\": lr_b,\n",
    "    \"batch_size\": batch_size_b,\n",
    "    \"epochs\": epochs_b\n",
    "}\n",
    "\n",
    "print(\"Best hyperparameters from hpo:\")\n",
    "print(\"lr:\",lr_b)\n",
    "print(\"batch_size:\",batch_size_b)\n",
    "print(\"epochs:\",epochs_b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Profiling and Debugging\n",
    "TODO: Using the best hyperparameters, create and finetune a new model\n",
    "\n",
    "**Note:** You will need to use the `train_model.py` script to perform model profiling and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up debugging and profiling rules and hooks\n",
    "\n",
    "\"\"\"\n",
    "#Define rules:\n",
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing(),\n",
    "                   rule_parameters={\"tensor_regex\": \"CrossEntropyLoss_output_0\",\"mode\": \"TRAIN\"}),#forum\n",
    "    #ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "    #Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    #Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "]\n",
    "\n",
    "#Define hooks\n",
    "from sagemaker.debugger import DebuggerHookConfig, ProfilerConfig, FrameworkProfile\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")\n",
    "\n",
    "debugger_config = DebuggerHookConfig(\n",
    "    hook_parameters={\"train.save_interval\": \"100\", \"eval.save_interval\": \"10\"}\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "#a revisar y borrar\n",
    "#collection_configs=[CollectionConfig(name=\"CrossEntropyLoss_output_0\",parameters={\n",
    "#    \"include_regex\": \"CrossEntropyLoss_output_0\", \"train.save_interval\": \"10\",\"eval.save_interval\": \"1\"})]\n",
    "#debugger_config=DebuggerHookConfig( collection_configs=collection_configs )\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Set up debugging and profiling rules and hooks\n",
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "\n",
    "rules = [\n",
    "    Rule.sagemaker(base_config=rule_configs.loss_not_decreasing(),\n",
    "                     rule_parameters={\"tensor_regex\": \"CrossEntropyLoss_output_0\",\n",
    "                                     \"mode\": \"TRAIN\"}),#forum\n",
    "    #ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "    #Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    #Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "]\n",
    "\n",
    "#Define the hooks\n",
    "from sagemaker.debugger import DebuggerHookConfig, ProfilerConfig, FrameworkProfile\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")\n",
    "debugger_config = DebuggerHookConfig(\n",
    "    hook_parameters={\"train.save_interval\": \"100\", \"eval.save_interval\": \"10\"}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-13 15:53:44 Starting - Starting the training job...\n",
      "2022-01-13 15:54:10 Starting - Launching requested ML instancesLossNotDecreasing: InProgress\n",
      "VanishingGradient: InProgress\n",
      "Overfit: InProgress\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: InProgress\n",
      "LowGPUUtilization: InProgress\n",
      "ProfilerReport: InProgress\n",
      "......\n",
      "2022-01-13 15:55:11 Starting - Preparing the instances for training.........\n",
      "2022-01-13 15:56:38 Downloading - Downloading input data.........\n",
      "2022-01-13 15:58:12 Training - Downloading the training image.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-01-13 15:58:17,579 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-01-13 15:58:17,581 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-13 15:58:17,589 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-01-13 15:58:20,611 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\n",
      "2022-01-13 15:58:39 Training - Training image download completed. Training in progress.\u001b[34m2022-01-13 15:58:36,334 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-13 15:58:36,345 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-13 15:58:36,354 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-13 15:58:36,363 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 257,\n",
      "        \"lr\": 0.09223091926609225,\n",
      "        \"epochs\": 4\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-01-13-15-53-43-599\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://project3dogsimagesclassification/pytorch-training-2022-01-13-15-53-43-599/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_model\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_model.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":257,\"epochs\":4,\"lr\":0.09223091926609225}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_model.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_model\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://project3dogsimagesclassification/pytorch-training-2022-01-13-15-53-43-599/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":257,\"epochs\":4,\"lr\":0.09223091926609225},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-01-13-15-53-43-599\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://project3dogsimagesclassification/pytorch-training-2022-01-13-15-53-43-599/source/sourcedir.tar.gz\",\"module_name\":\"train_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_model.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"257\",\"--epochs\",\"4\",\"--lr\",\"0.09223091926609225\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=257\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.09223091926609225\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=4\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_model.py --batch_size 257 --epochs 4 --lr 0.09223091926609225\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:38.013 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:38.361 algo-1:26 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.\u001b[0m\n",
      "\u001b[34mHyperparameters: epoch: 4, lr: 0.09223091926609225, batch size: 257, momentum: 0.5\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:39.543 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:39.545 algo-1:26 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:39.546 algo-1:26 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:39.546 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:43.055 algo-1:26 INFO hook.py:591] name:fc.0.weight count_params:68096\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:43.055 algo-1:26 INFO hook.py:591] name:fc.0.bias count_params:133\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:43.056 algo-1:26 INFO hook.py:593] Total Trainable Params: 68229\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:43.056 algo-1:26 INFO hook.py:425] Monitoring the collections: relu_input, losses, gradients\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:43.057 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/prestepzero-*-start-1642089518362099.0_train-0-stepstart-1642089523057392.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:43.070 algo-1:26 INFO hook.py:488] Hook is writing from the hook with pid: 26\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:54.265 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-0-stepstart-1642089523065812.8_train-0-forwardpassend-1642089534264619.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:58:59.878 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-0-forwardpassend-1642089534269939.5_train-1-stepstart-1642089539878148.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:59:10.524 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-1-stepstart-1642089539881427.8_train-1-forwardpassend-1642089550524508.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:59:14.026 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-1-forwardpassend-1642089550526716.5_train-2-stepstart-1642089554025589.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:59:24.153 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-2-stepstart-1642089554028504.2_train-2-forwardpassend-1642089564018154.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:59:27.409 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-2-forwardpassend-1642089564155102.0_train-3-stepstart-1642089567408646.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:59:36.644 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-3-stepstart-1642089567411377.2_train-3-forwardpassend-1642089576644046.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:59:39.663 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-3-forwardpassend-1642089576645494.2_train-4-stepstart-1642089579662760.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:59:48.975 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-4-stepstart-1642089579665878.8_train-4-forwardpassend-1642089588975349.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 15:59:52.234 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-4-forwardpassend-1642089588976724.2_train-5-stepstart-1642089592233731.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 16:00:01.377 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-5-stepstart-1642089592236446.5_train-5-forwardpassend-1642089601376858.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 16:00:04.885 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-5-forwardpassend-1642089601378245.5_train-6-stepstart-1642089604885091.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 16:00:14.086 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-6-stepstart-1642089604887835.0_train-6-forwardpassend-1642089614085814.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 16:00:17.028 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-6-forwardpassend-1642089614087432.0_train-7-stepstart-1642089617028522.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 16:00:26.353 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-7-stepstart-1642089617031322.5_train-7-forwardpassend-1642089626353578.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 16:00:29.185 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-7-forwardpassend-1642089626355011.2_train-8-stepstart-1642089629185049.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 16:00:38.303 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-8-stepstart-1642089629187711.0_train-8-forwardpassend-1642089638302757.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 16:00:41.267 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-8-forwardpassend-1642089638304172.8_train-9-stepstart-1642089641266884.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 16:00:50.332 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-9-stepstart-1642089641269654.8_train-9-forwardpassend-1642089650332352.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-13 16:00:53.914 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-9-forwardpassend-1642089650334054.5_train-10-stepstart-1642089653913813.2/python_stats.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create and fit an estimator\n",
    "path =  \"s3://{}/dogImages\".format(bucket)\n",
    "#estimator = # TODO: Your estimator here\n",
    "\"\"\"\n",
    "estimator = PyTorch(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    instance_count=1,\n",
    "    #instance_type=\"ml.p3.2xlarge\",#this is too expensive\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    entry_point=\"train_model.py\",\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    hyperparameters=hyperparameters_b,\n",
    "    profiler_config=profiler_config,\n",
    "    debugger_hook_config=debugger_config,\n",
    "    rules=rules,\n",
    "    output_path=path\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "estimator = sagemaker.pytorch.estimator.PyTorch(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    instance_count=1,\n",
    "    #instance_type=\"ml.p3.2xlarge\",#this is too expensive\n",
    "    #instance_type=\"ml.c5.2xlarge\",\n",
    "    instance_type=\"ml.m5.large\",#much cheaper\n",
    "    entry_point=\"train_model.py\",\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    profiler_config=profiler_config,\n",
    "    debugger_hook_config=debugger_config,\n",
    "    hyperparameters = hyperparameters_b,\n",
    "    rules=rules,\n",
    "    output_path=path\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "estimator.fit({\n",
    "'train': path + '/train',     \n",
    "'valid': path + '/valid',  \n",
    "'test': path + '/test'     \n",
    "})\n",
    "\"\"\"\n",
    "\n",
    "estimator.fit({\n",
    "'train': path + '/train',     \n",
    "'test': path + '/test',      \n",
    "}, wait=True)\n",
    "\n",
    "#last job took 70 min as follows: #start: 8:53 end: 10:03. It is not necessary to run it again\n",
    "#this job started at 19:07 (00:07UTC) and finished at 19:37, so it took about 30min\n",
    "#started 9:53, finishing by 10:23\n",
    "#started 10:25, by 10:50\n",
    "#started 10:53, by 11:28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model_data = estimator.model_data\n",
    "print(\"Model artifact saved at:\\n\", pt_model_data)\n",
    "import boto3\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "print(f\"Training jobname: {training_job_name}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot a debugging output.\n",
    "#Checking Training Performance\n",
    "#From 4.8.SageMaker Debugger.rtfd\n",
    "import smdebug\n",
    "from smdebug.trials import create_trial\n",
    "from smdebug.core.modes import ModeKeys\n",
    "\n",
    "trial = create_trial(estimator.latest_job_debugger_artifacts_path())\n",
    "\n",
    "print(\"Tensor names:\",trial.tensor_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug import modes\n",
    "trial.tensor('CrossEntropyLoss_output_0').values(mode=modes.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.plot(trial.steps(mode=modes.TRAIN),\n",
    "         list(trial.tensor('CrossEntropyLoss_output_0').values(mode=modes.TRAIN).values()))\n",
    "plt.show\n",
    "\"\"\"\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot a debugging output.\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "\n",
    "def get_data(trial, tname, mode):\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps(mode=mode)\n",
    "    vals = []\n",
    "    for s in steps:\n",
    "        vals.append(tensor.value(s, mode=mode))\n",
    "    return steps, vals\n",
    "\n",
    "\n",
    "\n",
    "#finally the plot\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "\n",
    "def plot_tensor(trial, tensor_name):\n",
    "    steps_train, vals_train = get_data(trial, tensor_name, mode=ModeKeys.TRAIN)\n",
    "    print(\"loaded TRAIN data\")\n",
    "    steps_eval, vals_eval = get_data(trial, tensor_name, mode=ModeKeys.EVAL)\n",
    "    print(\"loaded EVAL data\")\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    host = host_subplot(111)\n",
    "\n",
    "    par = host.twiny()\n",
    "\n",
    "    host.set_xlabel(\"Steps (TRAIN)\")\n",
    "    par.set_xlabel(\"Steps (EVAL)\")\n",
    "    host.set_ylabel(tensor_name)\n",
    "\n",
    "    (p1,) = host.plot(steps_train, vals_train, label=tensor_name)\n",
    "    print(\"completed TRAIN plot\")\n",
    "    (p2,) = par.plot(steps_eval, vals_eval, label=\"val_\" + tensor_name)\n",
    "    print(\"completed EVAL plot\")\n",
    "    leg = plt.legend()\n",
    "\n",
    "    host.xaxis.get_label().set_color(p1.get_color())\n",
    "    leg.texts[0].set_color(p1.get_color())\n",
    "\n",
    "    par.xaxis.get_label().set_color(p2.get_color())\n",
    "    leg.texts[1].set_color(p2.get_color())\n",
    "\n",
    "    plt.ylabel(tensor_name)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "#plot_tensor(trial, \"nll_loss_output_0\")\n",
    "plot_tensor(trial,'CrossEntropyLoss_output_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it? \n",
    "\n",
    "\n",
    "The graph shows no sustained tendency for different the batch sets. Which is understable since there is \n",
    "\n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?\n",
    "\n",
    "\n",
    "Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?\n",
    "\n",
    "Batches could be shuffled to try to minimize this effect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the profiler output\n",
    "\n",
    "#From 4.9.SageMaker Profiler.rtfd\n",
    "\n",
    "\n",
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "\n",
    "tj = TrainingJob(training_job_name, region)\n",
    "tj.wait_for_sys_profiling_data_to_be_available()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.profiler.analysis.notebook_utils.timeline_charts import TimelineCharts\n",
    "\n",
    "system_metrics_reader = tj.get_systems_metrics_reader()\n",
    "system_metrics_reader.refresh_event_file_list()\n",
    "\n",
    "view_timeline_charts = TimelineCharts(\n",
    "    system_metrics_reader,\n",
    "    framework_metrics_reader=None,\n",
    "    select_dimensions=[\"CPU\", \"GPU\"],\n",
    "    select_events=[\"total\"],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "rule_output_path = estimator.output_path + estimator.latest_training_job.job_name + \"/rule-output\"\n",
    "print(f\"You will find the profiler report in {rule_output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 ls {rule_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 cp {rule_output_path} ./ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get the autogenerated folder name of profiler report\n",
    "profiler_report_name = [\n",
    "    rule[\"RuleConfigurationName\"]\n",
    "    for rule in estimator.latest_training_job.rule_job_summary()\n",
    "    if \"Profiler\" in rule[\"RuleConfigurationName\"]\n",
    "][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.HTML(filename=profiler_report_name + \"/profiler-output/profiler-report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=64,\n",
    "    destination_s3_uri=f\"s3://{bucket}/data_capture\",\n",
    ")\n",
    "\n",
    "# TODO: Add your deployment configuration like instance type and number of instances\n",
    "predictor=estimator.deploy(instance_type=\"ml.m5.large\", initial_instance_count=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run an prediction on the endpoint\n",
    "\n",
    "#image = # TODO: Your code to load and preprocess image to send to endpoint for prediction\n",
    "#response = predictor.predict(image)\n",
    "# TODO: Run an prediction on the endpoint\n",
    "# TODO: Your code to load and preprocess image to send to endpoint for prediction\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "testing_transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root=\"sample_image\", \n",
    "            transform=testing_transform)\n",
    "image = torch.utils.data.DataLoader(testset)\n",
    "for input, label in image:\n",
    "    print(predictor.predict(input))\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
